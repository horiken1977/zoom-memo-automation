const AIService = require('./aiService');
const AudioCompressionService = require('./audioCompressionService');
const fs = require('fs').promises;
const path = require('path');
const logger = require('../utils/logger');

class AudioSummaryService {
  constructor() {
    this.aiService = new AIService();
    this.audioCompressionService = new AudioCompressionService();
  }

  /**
   * å‹•ç”»ãƒãƒƒãƒ•ã‚¡ã‚’Geminiã§æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„å‡¦ç†ï¼ˆVercelç’°å¢ƒç”¨ï¼‰
   * @param {Buffer} videoBuffer - å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®Buffer
   * @param {string} fileName - ãƒ•ã‚¡ã‚¤ãƒ«å
   * @param {Object} meetingInfo - ä¼šè­°æƒ…å ±
   * @returns {Object} æ–‡å­—èµ·ã“ã—ã¨è¦ç´„ã®çµæœ
   */
  async processVideoBuffer(videoBuffer, fileName, meetingInfo) {
    try {
      logger.info(`Processing video buffer: ${fileName} (${videoBuffer.length} bytes)`);

      // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºç¢ºèª
      logger.info(`Video buffer size: ${(videoBuffer.length / 1024 / 1024).toFixed(2)} MB`);

      // å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œè¨¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ï¼‰
      if (!fileName.toLowerCase().endsWith('.mp4')) {
        throw new Error(`Unsupported video format: ${fileName}. Only MP4 is supported.`);
      }

      // Gemini AIã§å‹•ç”»ã‹ã‚‰ç›´æ¥æ–‡å­—èµ·ã“ã—ãƒ»è¦ç´„å‡¦ç†
      // æ³¨ï¼šGemini 2.0ä»¥é™ã¯å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç›´æ¥å‡¦ç†å¯èƒ½
      return await this.processRealVideoBuffer(videoBuffer, fileName, meetingInfo);

    } catch (error) {
      logger.error('Failed to process video buffer:', error.message);
      throw error;
    }
  }

  /**
   * å®Ÿéš›ã®å‹•ç”»ãƒãƒƒãƒ•ã‚¡ã‚’å‡¦ç†ï¼ˆVercelç’°å¢ƒç”¨ï¼‰
   * Gemini 2.0ä»¥é™å¯¾å¿œ
   */
  async processRealVideoBuffer(videoBuffer, fileName, meetingInfo) {
    const startTime = Date.now();
    const debugTimer = (step, detail = '') => {
      const elapsed = Date.now() - startTime;
      logger.info(`ğŸ¬ VideoSummaryService [${elapsed}ms] ${step} ${detail}`);
      return elapsed;
    };

    try {
      debugTimer('processRealVideoBufferé–‹å§‹', `fileName: ${fileName}, bufferSize: ${videoBuffer.length}`);
      
      // Gemini AIã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
      debugTimer('Step 1: AI ServiceåˆæœŸåŒ–');
      const modelName = await this.aiService.initializeModel();
      debugTimer('Step 1: AI ServiceåˆæœŸåŒ–å®Œäº†', `model: ${modelName}`);
      
      // å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—
      debugTimer('Step 2: å‹•ç”»æ–‡å­—èµ·ã“ã—é–‹å§‹');
      const transcriptionResult = await this.aiService.transcribeVideoBuffer(
        videoBuffer,
        fileName
      );
      const transcriptionTime = debugTimer('Step 2: å‹•ç”»æ–‡å­—èµ·ã“ã—å®Œäº†', 
        `æ–‡å­—æ•°: ${transcriptionResult?.transcription?.length || 0}`
      );
      
      // æ–‡å­—èµ·ã“ã—ã‹ã‚‰è¦ç´„ç”Ÿæˆ
      debugTimer('Step 3: æ§‹é€ åŒ–è¦ç´„ç”Ÿæˆé–‹å§‹');
      const summaryResult = await this.generateStructuredSummary(
        transcriptionResult
      );
      const summaryTime = debugTimer('Step 3: æ§‹é€ åŒ–è¦ç´„ç”Ÿæˆå®Œäº†');
      
      const totalTime = Date.now() - startTime;
      debugTimer('processRealVideoBufferå®Œäº†', `ç·å‡¦ç†æ™‚é–“: ${totalTime}ms`);
      
      return {
        transcription: transcriptionResult,
        structuredSummary: summaryResult,
        processingTime: {
          transcription: transcriptionTime,
          summary: summaryTime,
          total: totalTime
        },
        processedFrom: 'video',
        fileName: fileName,
        fileSize: videoBuffer.length,
        model: modelName
      };
      
    } catch (error) {
      const elapsed = Date.now() - startTime;
      logger.error(`ğŸ¬ VideoSummaryService [${elapsed}ms] ã‚¨ãƒ©ãƒ¼:`, error.message);
      throw error;
    }
  }

  /**
   * éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚’Geminiã§æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„å‡¦ç†ï¼ˆVercelç’°å¢ƒç”¨ï¼‰
   * @param {Buffer} audioBuffer - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®Buffer
   * @param {string} fileName - ãƒ•ã‚¡ã‚¤ãƒ«å
   * @param {Object} meetingInfo - ä¼šè­°æƒ…å ±
   * @returns {Object} æ–‡å­—èµ·ã“ã—ã¨è¦ç´„ã®çµæœ
   */
  async processAudioBuffer(audioBuffer, fileName, meetingInfo) {
    try {
      logger.info(`Processing audio buffer: ${fileName} (${audioBuffer.length} bytes)`);

      // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºç¢ºèª
      logger.info(`Audio buffer size: ${(audioBuffer.length / 1024).toFixed(2)} KB`);

      // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œè¨¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ï¼‰
      this.validateAudioFileByName(fileName);

      // å®Ÿéš›ã®éŸ³å£°ãƒãƒƒãƒ•ã‚¡å‡¦ç†
      return await this.processRealAudioBuffer(audioBuffer, fileName, meetingInfo);

    } catch (error) {
      logger.error('Failed to process audio buffer:', error.message);
      throw error;
    }
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Geminiã§æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„å‡¦ç†
   * @param {string} audioFilePath - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
   * @param {Object} meetingInfo - ä¼šè­°æƒ…å ±
   * @returns {Object} æ–‡å­—èµ·ã“ã—ã¨è¦ç´„ã®çµæœ
   */
  async processAudioFile(audioFilePath, meetingInfo) {
    try {
      logger.info(`Processing audio file: ${audioFilePath}`);

      // ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
      try {
        await fs.access(audioFilePath);
      } catch (error) {
        throw new Error(`Audio file not found: ${audioFilePath}`);
      }

      // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
      const stats = await fs.stat(audioFilePath);
      logger.info(`Audio file size: ${(stats.size / 1024).toFixed(2)} KB`);

      // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œè¨¼
      this.validateAudioFile(audioFilePath);

      // å®Ÿéš›ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
      return await this.processRealAudioFile(audioFilePath, meetingInfo);

    } catch (error) {
      logger.error('Failed to process audio file:', error.message);
      throw error;
    }
  }

  /**
   * å®Ÿéš›ã®éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚’å‡¦ç†ï¼ˆVercelç’°å¢ƒç”¨ï¼‰
   */
  async processRealAudioBuffer(audioBuffer, fileName, meetingInfo) {
    const startTime = Date.now();
    const debugTimer = (step, detail = '') => {
      const elapsed = Date.now() - startTime;
      logger.info(`ğŸ”§ AudioSummaryService [${elapsed}ms] ${step} ${detail}`);
      return elapsed;
    };

    try {
      debugTimer('processRealAudioBufferé–‹å§‹', `fileName: ${fileName}, bufferSize: ${audioBuffer.length}`);
      
      // 0. éŸ³å£°åœ§ç¸®å‡¦ç†ï¼ˆæ–‡å­—èµ·ã“ã—ç²¾åº¦å‘ä¸Šã®ãŸã‚ï¼‰
      debugTimer('Step 0: éŸ³å£°åœ§ç¸®å‡¦ç†é–‹å§‹');
      let processedAudioBuffer = audioBuffer;
      let compressionStats = null;
      let qualityCheckResult = null;
      
      // 0-1. éŸ³å£°å“è³ªãƒã‚§ãƒƒã‚¯
      debugTimer('Step 0-1: éŸ³å£°å“è³ªãƒã‚§ãƒƒã‚¯é–‹å§‹');
      qualityCheckResult = await this.checkAudioQuality(audioBuffer);
      debugTimer('Step 0-1: éŸ³å£°å“è³ªãƒã‚§ãƒƒã‚¯å®Œäº†', `å“è³ªä½ä¸‹: ${qualityCheckResult.isLowQuality}, RMS: ${qualityCheckResult.averageRMS?.toFixed(4) || 'N/A'}`);
      
      // éŸ³å£°å“è³ªãŒä½ã„å ´åˆã¯è­¦å‘Šã‚’å‡ºåŠ›ï¼ˆãŸã ã—å‡¦ç†ã¯ç¶™ç¶šï¼‰
      if (qualityCheckResult.isLowQuality) {
        const { ErrorManager } = require('../utils/errorCodes');
        const warningInfo = ErrorManager.createError('E_AUDIO_QUALITY_WARNING', {
          meetingTopic: meetingInfo?.topic || 'Unknown',
          fileName: fileName,
          qualityDetails: qualityCheckResult.details
        });
        
        logger.warn('âš ï¸ éŸ³å£°å“è³ªè­¦å‘ŠãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:', warningInfo);
        
        // å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’å†æŠ½å‡ºã™ã‚‹å‡¦ç†ã‚’ã“ã“ã«è¿½åŠ å¯èƒ½
        // TODO: VideoStorageServiceã¨é€£æºã—ã¦å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’å†æŠ½å‡º
        // const videoService = new VideoStorageService();
        // if (meetingInfo.videoAvailable) {
        //   processedAudioBuffer = await videoService.extractAudioFromVideo(meetingInfo.videoPath);
        //   logger.info('å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’å†æŠ½å‡ºã—ã¾ã—ãŸ');
        // }
      }
      
      // 0-2. éŸ³å£°åœ§ç¸®å‡¦ç†
      if (this.audioCompressionService.shouldCompress(audioBuffer.length)) {
        logger.info('ğŸ—œï¸ å¤§å®¹é‡éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º - æœ€é«˜ãƒ¬ãƒ™ãƒ«åœ§ç¸®ã‚’å®Ÿè¡Œ');
        const compressionResult = await this.audioCompressionService.compressAudioBuffer(audioBuffer, fileName);
        processedAudioBuffer = compressionResult.compressedBuffer;
        compressionStats = compressionResult;
        debugTimer('Step 0: éŸ³å£°åœ§ç¸®å®Œäº†', `åœ§ç¸®ç‡: ${compressionResult.compressionRatio}%, ${Math.round(compressionResult.originalSize/1024/1024*100)/100}MB â†’ ${Math.round(compressionResult.compressedSize/1024/1024*100)/100}MB`);
      } else {
        debugTimer('Step 0: éŸ³å£°åœ§ç¸®ã‚¹ã‚­ãƒƒãƒ—', '10MBæœªæº€ã®ãŸã‚åœ§ç¸®ä¸è¦');
      }
      
      // 1. çµ±åˆAIå‡¦ç†ï¼ˆæ–‡å­—èµ·ã“ã—ï¼‹æ§‹é€ åŒ–è¦ç´„ã‚’1å›ã®APIå‘¼ã³å‡ºã—ã§å®Ÿè¡Œã€5å›ãƒªãƒˆãƒ©ã‚¤ä»˜ãï¼‰
      debugTimer('Step 1: processAudioWithStructuredOutputé–‹å§‹ï¼ˆçµ±åˆAIå‡¦ç†ï¼‰');
      logger.info('Starting unified audio processing with Gemini (transcription + structured summary)...');
      
      const unifiedResult = await this.aiService.processAudioWithStructuredOutput(processedAudioBuffer, fileName, meetingInfo);
      debugTimer('Step 1: processAudioWithStructuredOutputå®Œäº†', `transcription length: ${unifiedResult?.transcription?.length || 0}, summary generated: ${!!unifiedResult?.structuredSummary}`);
      
      // çµ±åˆçµæœã‹ã‚‰å€‹åˆ¥ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
      const transcriptionResult = {
        transcription: unifiedResult.transcription,
        meetingInfo: unifiedResult.meetingInfo,
        fileName: fileName,
        timestamp: unifiedResult.timestamp,
        audioBufferSize: unifiedResult.audioBufferSize,
        model: unifiedResult.model,
        attempt: unifiedResult.attempt
      };
      
      const structuredSummary = unifiedResult.structuredSummary;

      // 2. çµæœã®æ¤œè¨¼
      debugTimer('Step 2: validateProcessingResulté–‹å§‹');
      this.validateProcessingResult({ transcription: transcriptionResult, structuredSummary: structuredSummary });
      debugTimer('Step 2: validateProcessingResultå®Œäº†');
      
      const totalTime = debugTimer('processRealAudioBufferå®Œäº†');
      
      return {
        status: 'success',
        transcription: transcriptionResult,
        structuredSummary: structuredSummary, // TC203ã§æœŸå¾…ã•ã‚Œã‚‹æ§‹é€ 
        analysis: structuredSummary,
        audioFileName: fileName,
        audioBufferSize: audioBuffer.length,
        processedAudioBufferSize: processedAudioBuffer.length,
        compressionStats: compressionStats, // åœ§ç¸®çµ±è¨ˆæƒ…å ±
        qualityCheckResult: qualityCheckResult, // éŸ³å£°å“è³ªãƒã‚§ãƒƒã‚¯çµæœ
        meetingInfo: meetingInfo,
        processedAt: new Date().toISOString(),
        totalProcessingTime: totalTime,
        // çµ±åˆAIå‡¦ç†ã®è¿½åŠ æƒ…å ±
        apiCallReduction: '50%', // 2å›â†’1å›ã®APIå‘¼ã³å‡ºã—å‰Šæ¸›
        retryCapability: '5å›ãƒªãƒˆãƒ©ã‚¤å¯¾å¿œ',
        unifiedProcessing: true
      };

    } catch (error) {
      logger.error('Failed to process real audio buffer:', error.message);
      throw error;
    }
  }

  /**
   * å®Ÿéš›ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
   */
  async processRealAudioFile(audioFilePath, meetingInfo) {
    try {
      // 1. éŸ³å£°ã®æ–‡å­—èµ·ã“ã—
      logger.info('Starting audio transcription with Gemini...');
      const transcriptionResult = await this.aiService.transcribeAudio(audioFilePath, meetingInfo);

      // 2. æ§‹é€ åŒ–ã•ã‚ŒãŸè¦ç´„ã‚’ç”Ÿæˆ
      logger.info('Generating structured summary...');
      const structuredSummary = await this.generateStructuredSummary(transcriptionResult);

      // 3. çµæœã®æ¤œè¨¼
      this.validateProcessingResult({ transcription: transcriptionResult, analysis: structuredSummary });

      return {
        status: 'success',
        transcription: transcriptionResult,
        analysis: structuredSummary,
        audioFilePath: audioFilePath,
        meetingInfo: meetingInfo,
        processedAt: new Date().toISOString()
      };

    } catch (error) {
      logger.error('Failed to process real audio file:', error.message);
      throw error;
    }
  }

  /**
   * å‹•ç”»ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰éŸ³å£°ã¨ã—ã¦æ–‡å­—èµ·ã“ã—ãƒ»è¦ç´„å‡¦ç†
   * @param {Buffer} videoBuffer - å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®Buffer
   * @param {string} videoFileName - å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«å
   * @param {Object} meetingInfo - ä¼šè­°æƒ…å ±
   * @returns {Object} æ–‡å­—èµ·ã“ã—ã¨è¦ç´„ã®çµæœ
   */
  async processVideoAsAudio(videoBuffer, videoFileName, meetingInfo) {
    try {
      logger.info(`å‹•ç”»ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰éŸ³å£°å‡¦ç†é–‹å§‹: ${videoFileName} (${Math.round(videoBuffer.length / 1024 / 1024)}MB)`);

      // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºç¢ºèª
      const bufferSizeMB = videoBuffer.length / 1024 / 1024;
      logger.info(`Video buffer size: ${bufferSizeMB.toFixed(2)} MB`);

      // Gemini AI 20MBåˆ¶é™ãƒã‚§ãƒƒã‚¯
      const maxGeminiSize = 20 * 1024 * 1024;
      if (videoBuffer.length > maxGeminiSize) {
        logger.warn(`å‹•ç”»ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºãŒ20MBåˆ¶é™ã‚’è¶…é: ${bufferSizeMB.toFixed(2)}MB > 20MB`);
        logger.warn('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãªã—ãƒ»å¤§å®¹é‡å‹•ç”»ã®ãŸã‚ã€æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™');
        
        // TC206-S1ç”¨ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        throw new Error(`å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã™ãã‚‹ãŸã‚ã€æ–‡å­—èµ·ã“ã—ã§ãã¾ã›ã‚“ï¼ˆ${bufferSizeMB.toFixed(2)}MB > 20MBåˆ¶é™ï¼‰ã€‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚`);
      }

      // Gemini AI ã§å‹•ç”»ã‹ã‚‰éŸ³å£°æ–‡å­—èµ·ã“ã—ï¼ˆå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æ–‡å­—èµ·ã“ã—å¯èƒ½ï¼‰
      const transcription = await this.aiService.transcribeVideoBuffer(videoBuffer, videoFileName);
      
      if (!transcription || !transcription.transcription) {
        throw new Error('å‹•ç”»ã‹ã‚‰ã®æ–‡å­—èµ·ã“ã—ã«å¤±æ•—ã—ã¾ã—ãŸ');
      }

      logger.info(`å‹•ç”»æ–‡å­—èµ·ã“ã—å®Œäº†: ${transcription.transcription.length}æ–‡å­—`);

      // è¦ç´„ç”Ÿæˆ
      const summary = await this.generateStructuredSummary(transcription.transcription, meetingInfo);

      const result = {
        transcription: transcription,
        structuredSummary: summary,
        processingTime: Date.now() - Date.now(),
        isFromVideo: true,
        warnings: ['éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã§ã—ãŸ', 'ä»£æ›¿å‡¦ç†: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡ºã—ã¦æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ', 'å‡¦ç†çµæœ: æ­£å¸¸ã«å®Œäº†']
      };

      logger.info(`å‹•ç”»ã‹ã‚‰éŸ³å£°å‡¦ç†å®Œäº†: æ–‡å­—èµ·ã“ã—${transcription.transcription.length}æ–‡å­—, è¦ç´„ç”Ÿæˆ${!!summary}`);
      return result;

    } catch (error) {
      logger.error(`å‹•ç”»éŸ³å£°å‡¦ç†ã‚¨ãƒ©ãƒ¼: ${error.message}`);
      throw error;
    }
  }

  /**
   * 8é …ç›®ã®æ çµ„ã¿ã«æ²¿ã£ãŸæ§‹é€ åŒ–è¦ç´„ã‚’ç”Ÿæˆ
   */
  async generateStructuredSummary(transcriptionResult) {
    try {
      await this.aiService.initializeModel();

      const structuredPrompt = `ä»¥ä¸‹ã®ä¼šè­°éŸ³å£°ã®æ–‡å­—èµ·ã“ã—å†…å®¹ã‚’ã€æŒ‡å®šã•ã‚ŒãŸ8é …ç›®ã®æ çµ„ã¿ã«æ²¿ã£ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚

## ä¼šè­°æ–‡å­—èµ·ã“ã—å†…å®¹ï¼š
${transcriptionResult.transcription}

## è¦æ±‚ã™ã‚‹è¦ç´„å½¢å¼ï¼š
ä»¥ä¸‹ã®8é …ç›®ã«æ²¿ã£ã¦è©³ç´°ã«åˆ†æãƒ»è¦ç´„ã—ã¦ãã ã•ã„ï¼š

**1. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå**
ï¼ˆä¼šè­°å†…å®¹ã‹ã‚‰æ¨æ¸¬ã•ã‚Œã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåãƒ»çµ„ç¹”åãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’è¨˜è¼‰ã€‚å†…éƒ¨ä¼šè­°ã®å ´åˆã¯ã€Œå†…éƒ¨ä¼šè­°ã€ã¨è¨˜è¼‰ï¼‰

**2. ä¼šè­°ç›®çš„**
ï¼ˆãªãœã“ã®ä¼šè­°ãŒé–‹å‚¬ã•ã‚ŒãŸã‹ã€ä¼šè­°ã®ä¸»è¦ç›®æ¨™ã¯ä½•ã‹ï¼‰

**3. å‡ºå¸­è€…åãƒ»ç¤¾å**
ï¼ˆç™ºè¨€è€…ã‹ã‚‰åˆ¤åˆ¥ã•ã‚Œã‚‹å‚åŠ è€…ã®åå‰ãƒ»æ‰€å±çµ„ç¹”ã€å½¹è·ãŒåˆ†ã‹ã‚‹å ´åˆã¯è¨˜è¼‰ï¼‰

**4. è³‡æ–™**
ï¼ˆä¼šè­°ä¸­ã«è¨€åŠã•ã‚ŒãŸè³‡æ–™ã€æ–‡æ›¸ã€ãƒ‡ãƒ¼ã‚¿ã€ç”»é¢å…±æœ‰ã•ã‚ŒãŸå†…å®¹ç­‰ï¼‰

**5. è«–ç‚¹ãƒ»è­°è«–å†…å®¹**
ï¼ˆé‡è¦ï¼šä»¥ä¸‹ã®è¦³ç‚¹ã§è©³ç´°ã«è¨˜è¼‰ï¼‰
- èª°ãŒã©ã®ã‚ˆã†ãªç™ºè¨€ã‚’ã—ãŸã‹
- å„ç™ºè¨€è€…ã®ç«‹å ´ãƒ»è¦–ç‚¹
- è­°è«–ãŒã©ã®ã‚ˆã†ã«å±•é–‹ã—ã€ã©ã®ã‚ˆã†ãªè«–ç†ã®æµã‚Œã§é€²ã‚“ã ã‹
- å¯¾ç«‹ã™ã‚‹æ„è¦‹ãŒã‚ã£ãŸå ´åˆã¯ãã®å†…å®¹ã¨è§£æ±ºéç¨‹

**6. çµè«–ãƒ»æ±ºå®šäº‹é …**
ï¼ˆä¼šè­°ã§ç¢ºå®šã—ãŸäº‹é …ã€åˆæ„ã«é”ã—ãŸå†…å®¹ï¼‰

**7. å®¿é¡Œ**
ï¼ˆä»Šå¾Œèª¿æŸ»ãƒ»æ¤œè¨ãŒå¿…è¦ãªäº‹é …ã€æŒã¡å¸°ã‚Šæ¤œè¨é …ç›®ï¼‰

**8. Next Action / Due Date**
ï¼ˆå…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã¨å®Ÿè¡ŒæœŸé™ã€æ‹…å½“è€…ãŒåˆ†ã‹ã‚‹å ´åˆã¯è¨˜è¼‰ï¼‰

é‡è¦äº‹é …ï¼š
- å„é …ç›®ã«ã¤ã„ã¦ã€ä¼šè­°å†…å®¹ã«åŸºã¥ã„ã¦å…·ä½“çš„ã«è¨˜è¼‰ã—ã¦ãã ã•ã„
- ä¸æ˜ãªé …ç›®ã«ã¤ã„ã¦ã¯ã€Œä¸æ˜ã€ã¾ãŸã¯ã€Œè¨€åŠãªã—ã€ã¨æ˜è¨˜ã—ã¦ãã ã•ã„
- æ¨æ¸¬ã§ã¯ãªãã€å®Ÿéš›ã®ç™ºè¨€å†…å®¹ã«åŸºã¥ã„ã¦è¦ç´„ã—ã¦ãã ã•ã„`;

      const result = await this.aiService.model.generateContent(structuredPrompt);
      const response = await result.response;
      const summaryText = response.text();

      // æ§‹é€ åŒ–ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦è¿”ã™
      return {
        summary: summaryText,
        structure: 'eight_point_framework',
        keyPoints: this.extractKeyPoints(summaryText),
        meetingInfo: transcriptionResult.meetingInfo,
        timestamp: new Date().toISOString(),
        model: this.aiService.selectedModel
      };

    } catch (error) {
      logger.error('Failed to generate structured summary:', error.message);
      throw error;
    }
  }

  /**
   * è¦ç´„ã‹ã‚‰ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
   */
  extractKeyPoints(summaryText) {
    const keyPoints = [];
    const sections = summaryText.split(/\*\*\d+\./);
    
    sections.forEach((section, index) => {
      if (section.trim()) {
        const lines = section.split('\n').filter(line => line.trim());
        if (lines.length > 0) {
          keyPoints.push({
            section: index,
            title: lines[0].replace(/\*\*/g, '').trim(),
            content: lines.slice(1).join(' ').trim()
          });
        }
      }
    });

    return keyPoints;
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œè¨¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ï¼‰
   */
  validateAudioFileByName(fileName) {
    const ext = path.extname(fileName).toLowerCase();
    const supportedFormats = ['.mp3', '.m4a', '.wav', '.ogg', '.flac'];
    
    if (!supportedFormats.includes(ext)) {
      throw new Error(`Unsupported audio format: ${ext}. Supported formats: ${supportedFormats.join(', ')}`);
    }
    
    return true;
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œè¨¼
   */
  validateAudioFile(audioFilePath) {
    const ext = path.extname(audioFilePath).toLowerCase();
    const supportedFormats = ['.mp3', '.m4a', '.wav', '.ogg', '.flac'];
    
    if (!supportedFormats.includes(ext)) {
      throw new Error(`Unsupported audio format: ${ext}. Supported formats: ${supportedFormats.join(', ')}`);
    }
    
    return true;
  }

  /**
   * éŸ³å£°å“è³ªã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆç„¡éŸ³ã€æ¥µå°éŸ³é‡ã€éå‰°ãƒã‚¤ã‚ºã‚’æ¤œå‡ºï¼‰
   * @param {Buffer} audioBuffer - éŸ³å£°ãƒãƒƒãƒ•ã‚¡
   * @returns {Object} å“è³ªãƒã‚§ãƒƒã‚¯çµæœ
   */
  async checkAudioQuality(audioBuffer) {
    try {
      const bufferSize = audioBuffer.length;
      
      // ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼šæœ€åˆã€ä¸­é–“ã€æœ€å¾Œã®éƒ¨åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
      const sampleSize = Math.min(1024, Math.floor(bufferSize / 10));
      const startSample = audioBuffer.slice(0, sampleSize);
      const middleSample = audioBuffer.slice(Math.floor(bufferSize / 2) - sampleSize / 2, Math.floor(bufferSize / 2) + sampleSize / 2);
      const endSample = audioBuffer.slice(bufferSize - sampleSize, bufferSize);
      
      // éŸ³é‡ãƒ¬ãƒ™ãƒ«è¨ˆç®—ï¼ˆRMS: Root Mean Squareï¼‰
      const calculateRMS = (buffer) => {
        let sum = 0;
        for (let i = 0; i < buffer.length; i += 2) {
          const sample = buffer.readInt16LE(i) / 32768.0; // 16-bit audioæ­£è¦åŒ–
          sum += sample * sample;
        }
        return Math.sqrt(sum / (buffer.length / 2));
      };
      
      const startRMS = calculateRMS(startSample);
      const middleRMS = calculateRMS(middleSample);
      const endRMS = calculateRMS(endSample);
      const averageRMS = (startRMS + middleRMS + endRMS) / 3;
      
      // å“è³ªåˆ¤å®šåŸºæº–
      const isSilent = averageRMS < 0.001; // ã»ã¼ç„¡éŸ³
      const isVeryQuiet = averageRMS < 0.01; // æ¥µç«¯ã«å°ã•ã„éŸ³
      const hasHighNoise = averageRMS > 0.8; // ãƒã‚¤ã‚ºéå¤š
      
      const qualityResult = {
        averageRMS,
        isSilent,
        isVeryQuiet,
        hasHighNoise,
        isLowQuality: isSilent || isVeryQuiet || hasHighNoise,
        details: {
          startRMS,
          middleRMS,
          endRMS,
          threshold: {
            silent: 0.001,
            veryQuiet: 0.01,
            highNoise: 0.8
          }
        }
      };
      
      if (qualityResult.isLowQuality) {
        logger.warn('ğŸ”Š éŸ³å£°å“è³ªè­¦å‘Š:', {
          isSilent,
          isVeryQuiet,
          hasHighNoise,
          averageRMS: averageRMS.toFixed(4)
        });
      }
      
      return qualityResult;
    } catch (error) {
      logger.error('éŸ³å£°å“è³ªãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼:', error.message);
      // ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯å“è³ªãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦å‡¦ç†ç¶™ç¶š
      return {
        averageRMS: 0.5,
        isLowQuality: false,
        error: error.message
      };
    }
  }

  /**
   * å‡¦ç†çµæœã®æ¤œè¨¼
   */
  validateProcessingResult(result) {
    if (!result || !result.transcription) {
      throw new Error('Invalid processing result: missing required fields');
    }

    // æ§‹é€ åŒ–è¦ç´„ã®æ¤œè¨¼ï¼ˆæ–°å½¢å¼å¯¾å¿œï¼‰
    if (!result.structuredSummary && (!result.analysis || !result.analysis.summary)) {
      throw new Error('Invalid analysis result: missing structured summary');
    }

    return true;
  }

  /**
   * å‡¦ç†çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
   */
  getProcessingStats(result) {
    return {
      audioFileName: path.basename(result.audioFilePath),
      transcriptionLength: result.transcription.transcription ? result.transcription.transcription.length : 0,
      summaryLength: result.analysis.summary ? result.analysis.summary.length : 0,
      keyPointsCount: result.analysis.keyPoints ? result.analysis.keyPoints.length : 0,
      processingTime: result.processedAt,
      model: result.transcription.model || 'unknown',
      summaryStructure: result.analysis.structure || 'unknown'
    };
  }
}

module.exports = AudioSummaryService;