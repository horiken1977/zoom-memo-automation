const AIService = require('./aiService');
const AudioCompressionService = require('./audioCompressionService');
const fs = require('fs').promises;
const path = require('path');
const logger = require('../utils/logger');

class AudioSummaryService {
  constructor() {
    this.aiService = new AIService();
    this.audioCompressionService = new AudioCompressionService();
  }

  /**
   * éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚’Geminiã§æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„å‡¦ç†ï¼ˆVercelç’°å¢ƒç”¨ï¼‰
   * @param {Buffer} audioBuffer - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®Buffer
   * @param {string} fileName - ãƒ•ã‚¡ã‚¤ãƒ«å
   * @param {Object} meetingInfo - ä¼šè­°æƒ…å ±
   * @returns {Object} æ–‡å­—èµ·ã“ã—ã¨è¦ç´„ã®çµæœ
   */
  async processAudioBuffer(audioBuffer, fileName, meetingInfo) {
    try {
      logger.info(`Processing audio buffer: ${fileName} (${audioBuffer.length} bytes)`);

      // ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºç¢ºèª
      logger.info(`Audio buffer size: ${(audioBuffer.length / 1024).toFixed(2)} KB`);

      // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œè¨¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ï¼‰
      this.validateAudioFileByName(fileName);

      // å®Ÿéš›ã®éŸ³å£°ãƒãƒƒãƒ•ã‚¡å‡¦ç†
      return await this.processRealAudioBuffer(audioBuffer, fileName, meetingInfo);

    } catch (error) {
      logger.error('Failed to process audio buffer:', error.message);
      throw error;
    }
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Geminiã§æ–‡å­—èµ·ã“ã—ï¼†è¦ç´„å‡¦ç†
   * @param {string} audioFilePath - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
   * @param {Object} meetingInfo - ä¼šè­°æƒ…å ±
   * @returns {Object} æ–‡å­—èµ·ã“ã—ã¨è¦ç´„ã®çµæœ
   */
  async processAudioFile(audioFilePath, meetingInfo) {
    try {
      logger.info(`Processing audio file: ${audioFilePath}`);

      // ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
      try {
        await fs.access(audioFilePath);
      } catch (error) {
        throw new Error(`Audio file not found: ${audioFilePath}`);
      }

      // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
      const stats = await fs.stat(audioFilePath);
      logger.info(`Audio file size: ${(stats.size / 1024).toFixed(2)} KB`);

      // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œè¨¼
      this.validateAudioFile(audioFilePath);

      // å®Ÿéš›ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
      return await this.processRealAudioFile(audioFilePath, meetingInfo);

    } catch (error) {
      logger.error('Failed to process audio file:', error.message);
      throw error;
    }
  }

  /**
   * å®Ÿéš›ã®éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚’å‡¦ç†ï¼ˆVercelç’°å¢ƒç”¨ï¼‰
   */
  async processRealAudioBuffer(audioBuffer, fileName, meetingInfo) {
    const startTime = Date.now();
    const debugTimer = (step, detail = '') => {
      const elapsed = Date.now() - startTime;
      logger.info(`ğŸ”§ AudioSummaryService [${elapsed}ms] ${step} ${detail}`);
      return elapsed;
    };

    try {
      debugTimer('processRealAudioBufferé–‹å§‹', `fileName: ${fileName}, bufferSize: ${audioBuffer.length}`);
      
      // 0. éŸ³å£°åœ§ç¸®å‡¦ç†ï¼ˆæ–‡å­—èµ·ã“ã—ç²¾åº¦å‘ä¸Šã®ãŸã‚ï¼‰
      debugTimer('Step 0: éŸ³å£°åœ§ç¸®å‡¦ç†é–‹å§‹');
      let processedAudioBuffer = audioBuffer;
      let compressionStats = null;
      
      if (this.audioCompressionService.shouldCompress(audioBuffer.length)) {
        logger.info('ğŸ—œï¸ å¤§å®¹é‡éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º - æœ€é«˜ãƒ¬ãƒ™ãƒ«åœ§ç¸®ã‚’å®Ÿè¡Œ');
        const compressionResult = await this.audioCompressionService.compressAudioBuffer(audioBuffer, fileName);
        processedAudioBuffer = compressionResult.compressedBuffer;
        compressionStats = compressionResult;
        debugTimer('Step 0: éŸ³å£°åœ§ç¸®å®Œäº†', `åœ§ç¸®ç‡: ${compressionResult.compressionRatio}%, ${Math.round(compressionResult.originalSize/1024/1024*100)/100}MB â†’ ${Math.round(compressionResult.compressedSize/1024/1024*100)/100}MB`);
      } else {
        debugTimer('Step 0: éŸ³å£°åœ§ç¸®ã‚¹ã‚­ãƒƒãƒ—', '10MBæœªæº€ã®ãŸã‚åœ§ç¸®ä¸è¦');
      }
      
      // 1. éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ï¼ˆåœ§ç¸®æ¸ˆã¿Bufferã‹ã‚‰ï¼‰
      debugTimer('Step 1: transcribeAudioFromBufferé–‹å§‹');
      logger.info('Starting audio transcription from buffer with Gemini...');
      
      const transcriptionResult = await this.aiService.transcribeAudioFromBuffer(processedAudioBuffer, fileName, meetingInfo);
      debugTimer('Step 1: transcribeAudioFromBufferå®Œäº†', `transcription length: ${transcriptionResult?.transcription?.length || 0}`);
      
      // 2. æ§‹é€ åŒ–ã•ã‚ŒãŸè¦ç´„ã‚’ç”Ÿæˆ
      debugTimer('Step 2: generateStructuredSummaryé–‹å§‹');
      logger.info('Generating structured summary...');
      const structuredSummary = await this.generateStructuredSummary(transcriptionResult);
      debugTimer('Step 2: generateStructuredSummaryå®Œäº†');

      // 3. çµæœã®æ¤œè¨¼
      debugTimer('Step 3: validateProcessingResulté–‹å§‹');
      this.validateProcessingResult({ transcription: transcriptionResult, structuredSummary: structuredSummary });
      debugTimer('Step 3: validateProcessingResultå®Œäº†');
      
      const totalTime = debugTimer('processRealAudioBufferå®Œäº†');
      
      return {
        status: 'success',
        transcription: transcriptionResult,
        structuredSummary: structuredSummary, // TC203ã§æœŸå¾…ã•ã‚Œã‚‹æ§‹é€ 
        analysis: structuredSummary,
        audioFileName: fileName,
        audioBufferSize: audioBuffer.length,
        processedAudioBufferSize: processedAudioBuffer.length,
        compressionStats: compressionStats, // åœ§ç¸®çµ±è¨ˆæƒ…å ±
        meetingInfo: meetingInfo,
        processedAt: new Date().toISOString(),
        totalProcessingTime: totalTime
      };

    } catch (error) {
      logger.error('Failed to process real audio buffer:', error.message);
      throw error;
    }
  }

  /**
   * å®Ÿéš›ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
   */
  async processRealAudioFile(audioFilePath, meetingInfo) {
    try {
      // 1. éŸ³å£°ã®æ–‡å­—èµ·ã“ã—
      logger.info('Starting audio transcription with Gemini...');
      const transcriptionResult = await this.aiService.transcribeAudio(audioFilePath, meetingInfo);

      // 2. æ§‹é€ åŒ–ã•ã‚ŒãŸè¦ç´„ã‚’ç”Ÿæˆ
      logger.info('Generating structured summary...');
      const structuredSummary = await this.generateStructuredSummary(transcriptionResult);

      // 3. çµæœã®æ¤œè¨¼
      this.validateProcessingResult({ transcription: transcriptionResult, analysis: structuredSummary });

      return {
        status: 'success',
        transcription: transcriptionResult,
        analysis: structuredSummary,
        audioFilePath: audioFilePath,
        meetingInfo: meetingInfo,
        processedAt: new Date().toISOString()
      };

    } catch (error) {
      logger.error('Failed to process real audio file:', error.message);
      throw error;
    }
  }

  /**
   * 8é …ç›®ã®æ çµ„ã¿ã«æ²¿ã£ãŸæ§‹é€ åŒ–è¦ç´„ã‚’ç”Ÿæˆ
   */
  async generateStructuredSummary(transcriptionResult) {
    try {
      await this.aiService.initializeModel();

      const structuredPrompt = `ä»¥ä¸‹ã®ä¼šè­°éŸ³å£°ã®æ–‡å­—èµ·ã“ã—å†…å®¹ã‚’ã€æŒ‡å®šã•ã‚ŒãŸ8é …ç›®ã®æ çµ„ã¿ã«æ²¿ã£ã¦è¦ç´„ã—ã¦ãã ã•ã„ã€‚

## ä¼šè­°æ–‡å­—èµ·ã“ã—å†…å®¹ï¼š
${transcriptionResult.transcription}

## è¦æ±‚ã™ã‚‹è¦ç´„å½¢å¼ï¼š
ä»¥ä¸‹ã®8é …ç›®ã«æ²¿ã£ã¦è©³ç´°ã«åˆ†æãƒ»è¦ç´„ã—ã¦ãã ã•ã„ï¼š

**1. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå**
ï¼ˆä¼šè­°å†…å®¹ã‹ã‚‰æ¨æ¸¬ã•ã‚Œã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåãƒ»çµ„ç¹”åãƒ»ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’è¨˜è¼‰ã€‚å†…éƒ¨ä¼šè­°ã®å ´åˆã¯ã€Œå†…éƒ¨ä¼šè­°ã€ã¨è¨˜è¼‰ï¼‰

**2. ä¼šè­°ç›®çš„**
ï¼ˆãªãœã“ã®ä¼šè­°ãŒé–‹å‚¬ã•ã‚ŒãŸã‹ã€ä¼šè­°ã®ä¸»è¦ç›®æ¨™ã¯ä½•ã‹ï¼‰

**3. å‡ºå¸­è€…åãƒ»ç¤¾å**
ï¼ˆç™ºè¨€è€…ã‹ã‚‰åˆ¤åˆ¥ã•ã‚Œã‚‹å‚åŠ è€…ã®åå‰ãƒ»æ‰€å±çµ„ç¹”ã€å½¹è·ãŒåˆ†ã‹ã‚‹å ´åˆã¯è¨˜è¼‰ï¼‰

**4. è³‡æ–™**
ï¼ˆä¼šè­°ä¸­ã«è¨€åŠã•ã‚ŒãŸè³‡æ–™ã€æ–‡æ›¸ã€ãƒ‡ãƒ¼ã‚¿ã€ç”»é¢å…±æœ‰ã•ã‚ŒãŸå†…å®¹ç­‰ï¼‰

**5. è«–ç‚¹ãƒ»è­°è«–å†…å®¹**
ï¼ˆé‡è¦ï¼šä»¥ä¸‹ã®è¦³ç‚¹ã§è©³ç´°ã«è¨˜è¼‰ï¼‰
- èª°ãŒã©ã®ã‚ˆã†ãªç™ºè¨€ã‚’ã—ãŸã‹
- å„ç™ºè¨€è€…ã®ç«‹å ´ãƒ»è¦–ç‚¹
- è­°è«–ãŒã©ã®ã‚ˆã†ã«å±•é–‹ã—ã€ã©ã®ã‚ˆã†ãªè«–ç†ã®æµã‚Œã§é€²ã‚“ã ã‹
- å¯¾ç«‹ã™ã‚‹æ„è¦‹ãŒã‚ã£ãŸå ´åˆã¯ãã®å†…å®¹ã¨è§£æ±ºéç¨‹

**6. çµè«–ãƒ»æ±ºå®šäº‹é …**
ï¼ˆä¼šè­°ã§ç¢ºå®šã—ãŸäº‹é …ã€åˆæ„ã«é”ã—ãŸå†…å®¹ï¼‰

**7. å®¿é¡Œ**
ï¼ˆä»Šå¾Œèª¿æŸ»ãƒ»æ¤œè¨ãŒå¿…è¦ãªäº‹é …ã€æŒã¡å¸°ã‚Šæ¤œè¨é …ç›®ï¼‰

**8. Next Action / Due Date**
ï¼ˆå…·ä½“çš„ãªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã¨å®Ÿè¡ŒæœŸé™ã€æ‹…å½“è€…ãŒåˆ†ã‹ã‚‹å ´åˆã¯è¨˜è¼‰ï¼‰

é‡è¦äº‹é …ï¼š
- å„é …ç›®ã«ã¤ã„ã¦ã€ä¼šè­°å†…å®¹ã«åŸºã¥ã„ã¦å…·ä½“çš„ã«è¨˜è¼‰ã—ã¦ãã ã•ã„
- ä¸æ˜ãªé …ç›®ã«ã¤ã„ã¦ã¯ã€Œä¸æ˜ã€ã¾ãŸã¯ã€Œè¨€åŠãªã—ã€ã¨æ˜è¨˜ã—ã¦ãã ã•ã„
- æ¨æ¸¬ã§ã¯ãªãã€å®Ÿéš›ã®ç™ºè¨€å†…å®¹ã«åŸºã¥ã„ã¦è¦ç´„ã—ã¦ãã ã•ã„`;

      const result = await this.aiService.model.generateContent(structuredPrompt);
      const response = await result.response;
      const summaryText = response.text();

      // æ§‹é€ åŒ–ã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦è¿”ã™
      return {
        summary: summaryText,
        structure: 'eight_point_framework',
        keyPoints: this.extractKeyPoints(summaryText),
        meetingInfo: transcriptionResult.meetingInfo,
        timestamp: new Date().toISOString(),
        model: this.aiService.selectedModel
      };

    } catch (error) {
      logger.error('Failed to generate structured summary:', error.message);
      throw error;
    }
  }

  /**
   * è¦ç´„ã‹ã‚‰ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
   */
  extractKeyPoints(summaryText) {
    const keyPoints = [];
    const sections = summaryText.split(/\*\*\d+\./);
    
    sections.forEach((section, index) => {
      if (section.trim()) {
        const lines = section.split('\n').filter(line => line.trim());
        if (lines.length > 0) {
          keyPoints.push({
            section: index,
            title: lines[0].replace(/\*\*/g, '').trim(),
            content: lines.slice(1).join(' ').trim()
          });
        }
      }
    });

    return keyPoints;
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œè¨¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ï¼‰
   */
  validateAudioFileByName(fileName) {
    const ext = path.extname(fileName).toLowerCase();
    const supportedFormats = ['.mp3', '.m4a', '.wav', '.ogg', '.flac'];
    
    if (!supportedFormats.includes(ext)) {
      throw new Error(`Unsupported audio format: ${ext}. Supported formats: ${supportedFormats.join(', ')}`);
    }
    
    return true;
  }

  /**
   * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’æ¤œè¨¼
   */
  validateAudioFile(audioFilePath) {
    const ext = path.extname(audioFilePath).toLowerCase();
    const supportedFormats = ['.mp3', '.m4a', '.wav', '.ogg', '.flac'];
    
    if (!supportedFormats.includes(ext)) {
      throw new Error(`Unsupported audio format: ${ext}. Supported formats: ${supportedFormats.join(', ')}`);
    }
    
    return true;
  }

  /**
   * å‡¦ç†çµæœã®æ¤œè¨¼
   */
  validateProcessingResult(result) {
    if (!result || !result.transcription) {
      throw new Error('Invalid processing result: missing required fields');
    }

    // æ§‹é€ åŒ–è¦ç´„ã®æ¤œè¨¼ï¼ˆæ–°å½¢å¼å¯¾å¿œï¼‰
    if (!result.structuredSummary && (!result.analysis || !result.analysis.summary)) {
      throw new Error('Invalid analysis result: missing structured summary');
    }

    return true;
  }

  /**
   * å‡¦ç†çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
   */
  getProcessingStats(result) {
    return {
      audioFileName: path.basename(result.audioFilePath),
      transcriptionLength: result.transcription.transcription ? result.transcription.transcription.length : 0,
      summaryLength: result.analysis.summary ? result.analysis.summary.length : 0,
      keyPointsCount: result.analysis.keyPoints ? result.analysis.keyPoints.length : 0,
      processingTime: result.processedAt,
      model: result.transcription.model || 'unknown',
      summaryStructure: result.analysis.structure || 'unknown'
    };
  }
}

module.exports = AudioSummaryService;